{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4785eee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Already exposed function with name \"getEmotion\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b703fefa0f7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0meel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mgetEmotion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\eel\\__init__.py\u001b[0m in \u001b[0;36mexpose\u001b[1;34m(name_or_function)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname_or_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0m_expose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\anaconda\\lib\\site-packages\\eel\\__init__.py\u001b[0m in \u001b[0;36m_expose\u001b[1;34m(name, function)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Already exposed function with name \"%s\"'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_exposed_functions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m     \u001b[0m_exposed_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Already exposed function with name \"getEmotion\""
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "import cv2\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import Update_Model\n",
    "import glob\n",
    "import random\n",
    "import eel\n",
    "import light\n",
    "#import winsound\n",
    "\n",
    "frequency=2500\n",
    "duration=1000\n",
    "\n",
    "eel.init('WD')\n",
    "emotions=[\"angry\", \"happy\", \"sad\", \"neutral\"]\n",
    "fishface = cv2.face.FisherFaceRecognizer_create()\n",
    "#cv2.face.FisherFaceRecognizer_create()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "'''try:\n",
    "    fishface.load(\"model.xml\")\n",
    "except:\n",
    "    print(\"No trained model found... --update will create one.\")'''\n",
    "\n",
    "parser=argparse.ArgumentParser(description=\"Options for emotions based music player(Updating the model)\")\n",
    "parser.add_argument(\"--update\", help=\"Call for taking new images and retraining the model.\", action=\"store_true\")\n",
    "args=parser.parse_args()    \n",
    "facedict={}\n",
    "video_capture=cv2.VideoCapture(0)\n",
    "facecascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def crop(clahe_image, face):\n",
    "    for (x, y, w, h) in face:\n",
    "        faceslice=clahe_image[y:y+h, x:x+w]\n",
    "        faceslice=cv2.resize(faceslice, (350, 350))\n",
    "        facedict[\"face%s\" %(len(facedict)+1)]=faceslice\n",
    "    return faceslice\n",
    "\n",
    "def grab_face():\n",
    "    #ret, frame=video_capture.read()\n",
    "    ret, frame=light.nolight()\n",
    "    #cv2.imshow(\"Video\", frame)\n",
    "    cv2.imwrite('test.jpg', frame)\n",
    "    cv2.imwrite(\"images/main%s.jpg\" %count, frame)\n",
    "    gray=cv2.imread('test.jpg',0)\n",
    "    #gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    clahe=cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clahe_image=clahe.apply(gray)\n",
    "    return clahe_image\n",
    "\n",
    "def detect_face():\n",
    "    clahe_image=grab_face()\n",
    "    face=facecascade.detectMultiScale(clahe_image, scaleFactor=1.1, minNeighbors=15, minSize=(10, 10), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    if len(face)>=1:\n",
    "        faceslice=crop(clahe_image, face)\n",
    "        #return faceslice\n",
    "    else:\n",
    "        print(\"No/Multiple faces detected!!, passing over the frame\")\n",
    "\n",
    "def save_face(emotion):\n",
    "    print(\"\\n\\nLook \"+emotion+\" untill the timer expires and keep the same emotion for some time.\")\n",
    "    #winsound.Beep(frequency, duration)\n",
    "    print('\\a')\n",
    "    \n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        print(5-i)\n",
    "        time.sleep(1)\n",
    "    \n",
    "    while len(facedict.keys())<16:\n",
    "        detect_face()\n",
    "\n",
    "    for i in facedict.keys():\n",
    "        path, dirs, files = next(os.walk(\"dataset/%s\" %emotion))\n",
    "        file_count = len(files)+1\n",
    "        cv2.imwrite(\"dataset/%s/%s.jpg\" %(emotion, (file_count)), facedict[i])\n",
    "    facedict.clear()\n",
    "\n",
    "def update_model(emotions):\n",
    "    print(\"Update mode for model is ready\")\n",
    "    checkForFolders(emotions)\n",
    "    \n",
    "    for i in range(0, len(emotions)):\n",
    "        save_face(emotions[i])\n",
    "    print(\"Collected the images, looking nice! Now updating the model...\")\n",
    "    Update_Model.update(emotions)\n",
    "    print(\"Model train successful!!\")\n",
    "\n",
    "def checkForFolders(emotions):\n",
    "    for emotion in emotions:\n",
    "        if os.path.exists(\"dataset/%s\" %emotion):\n",
    "            pass\n",
    "        else:\n",
    "            os.makedirs(\"dataset/%s\" %emotion)\n",
    "\n",
    "def identify_emotions():\n",
    "    prediction=[]\n",
    "    confidence=[]\n",
    "\n",
    "    for i in facedict.keys():\n",
    "        pred, conf=fishface.predict(facedict[i])\n",
    "        cv2.imwrite(\"images/%s.jpg\" %i, facedict[i])\n",
    "        prediction.append(pred)\n",
    "        confidence.append(conf)\n",
    "    output=emotions[max(set(prediction), key=prediction.count)]    \n",
    "    print(\"You seem to be %s\" %output) \n",
    "    facedict.clear()\n",
    "    return output;\n",
    "    #songlist=[]\n",
    "    #songlist=sorted(glob.glob(\"songs/%s/*\" %output))\n",
    "    #random.shuffle(songlist)\n",
    "    #os.startfile(songlist[0])\n",
    "count=0\n",
    "@eel.expose\n",
    "def getEmotion():\n",
    "   \n",
    "    count=0\n",
    "    while True:\n",
    "        count=count+1\n",
    "        detect_face()\n",
    "        if args.update:\n",
    "            update_model(emotions)\n",
    "            break\n",
    "        elif count==10:\n",
    "            fishface.read(\"model2.xml\")\n",
    "            return identify_emotions()\n",
    "            break\n",
    "\n",
    "eel.start('main.html')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a439bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1289bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
